{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "from gpt.trainer import (Trainer, TrainerConfig, )\n",
    "from gpt.modeling import (GPT, GPT1Config, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizedDataset(tf.data.Dataset):\n",
    "    def _gen_examples_from(data: str, block_size: int):\n",
    "        def _gen():\n",
    "            nb_examples = len(data)-block_size\n",
    "            for idx in range(nb_examples):\n",
    "                # grab a chunk of (block_size + 1) characters from the data\n",
    "                chunk = data[idx:idx + block_size + 1]\n",
    "                x = tf.convert_to_tensor(chunk[:-1])\n",
    "                y = tf.convert_to_tensor(chunk[1:])\n",
    "                yield x, y\n",
    "        return _gen\n",
    "\n",
    "    def __new__(\n",
    "        cls, input_ids: List[int], block_size: int, batch_size: int\n",
    "    ):\n",
    "        # nb_examples = len(data)-block_size\n",
    "        dataset =  (\n",
    "            tf.data.Dataset.from_generator(\n",
    "                cls._gen_examples_from(input_ids, block_size),\n",
    "                output_signature=(\n",
    "                    tf.TensorSpec(shape=(block_size,), dtype=tf.int32),\n",
    "                    tf.TensorSpec(shape=(block_size,), dtype=tf.int32))\n",
    "                )\n",
    "                # .shuffle(nb_examples, reshuffle_each_iteration=True)\n",
    "                .batch(batch_size, drop_remainder=True)\n",
    "                .repeat()\n",
    "                .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        )\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 11:10:22.356991: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "BLOCK_SIZE=64\n",
    "BATCH_SIZE=512\n",
    "\n",
    "def encode_text_to_ids(tokenizer, text: str):\n",
    "    output = tokenizer.encode(text)\n",
    "    return output.ids\n",
    "\n",
    "pretrained_tokenizer = Tokenizer.from_file(\"./data/tokenizer.json\")\n",
    "vocab_size = pretrained_tokenizer.get_vocab_size()\n",
    "\n",
    "text = open(\"./data/tinyshakespeare.txt\").read()\n",
    "input_ids = encode_text_to_ids(pretrained_tokenizer, text)\n",
    "train_dataset = TokenizedDataset(\n",
    "    input_ids, block_size=BLOCK_SIZE, batch_size=BATCH_SIZE\n",
    ")\n",
    "nb_examples = len(input_ids)-BLOCK_SIZE\n",
    "nb_optimization_steps = nb_examples//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18145"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261907"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_optimization_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number optimization steps = 511\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=1\n",
    "LEARNING_RATE=0.003#6.25e-5\n",
    "\n",
    "total_number_optimization_steps = nb_optimization_steps * EPOCHS\n",
    "\n",
    "print(f\"total number optimization steps = {total_number_optimization_steps}\")\n",
    "\n",
    "config = GPT1Config(\n",
    "    vocab_size=vocab_size, block_size=BLOCK_SIZE,\n",
    "    n_layer=3, n_head=3, n_embd=48\n",
    ")\n",
    "tconf = TrainerConfig(\n",
    "    max_epochs=EPOCHS, batch_size=BATCH_SIZE, learning_rate=LEARNING_RATE,\n",
    "    do_lr_decay=True, warmup_ratio=0.1, cosine_decay_alpha=0.0,\n",
    "    total_number_optimization_steps=total_number_optimization_steps, log_every_steps=10,\n",
    "    ckpt_path='./logs', trial_id='shakespeare_token_level'\n",
    "    # warmup_tokens=0, final_tokens=0\n",
    "    # warmup_tokens=20*512, final_tokens=2*nb_examples*BLOCK_SIZE\n",
    ")\n",
    "\n",
    "model = GPT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model, train_dataset, total_number_optimization_steps, config=tconf\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"O God, O God!\"\n",
    "# x = tf.constant([stoi[s] for s in context], dtype=tf.int32)[None,...]\n",
    "x = tf.convert_to_tensor(pretrained_tokenizer.encode(context).ids, dtype=tf.int32)[None, ...]\n",
    "y = model.sample(x, 100, temperature=1.0, sample=True, top_k=10)[0]\n",
    "# completion = ''.join([itos[int(i)] for i in y])\n",
    "completion = pretrained_tokenizer.decode(y)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('mini-gpt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "946e8c0cc26320c95fa81a5ea73bdc05642666f24908863aa1da4c65c648eefa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
